# ğŸ§­ Projeto â€” ClassificaÃ§Ã£o e Clustering de Textos (20 Newsgroups - 6 classes)

**Disciplina:** ELE606 â€” TÃ³picos em IA  
**Professor:** JosÃ© Alfredo F. Costa  
**Aluno:** CauÃ£ Vitor  
**InstituiÃ§Ã£o:** UFRN â€” DEE â€” 2025.2

---

## ğŸ“‹ DescriÃ§Ã£o

Este projeto realiza classificaÃ§Ã£o e clustering de textos da base **20 Newsgroups** utilizando duas abordagens:

1. **VetorizaÃ§Ã£o clÃ¡ssica (TF-IDF)** com classificadores e algoritmos de clustering tradicionais
2. **Embeddings modernos (Google Gemini)** com os mesmos algoritmos para comparaÃ§Ã£o

O objetivo Ã© comparar o desempenho entre mÃ©todos clÃ¡ssicos e modernos de NLP em tarefas de classificaÃ§Ã£o e clustering.

---

## ğŸ“ Estrutura de DiretÃ³rios

```
ClassicVsModernNLP/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Dados brutos (se necessÃ¡rio)
â”‚   â””â”€â”€ processed/        # Dados prÃ©-processados e vetorizados
â”‚
â”œâ”€â”€ notebooks/            # Notebooks Jupyter em ordem sequencial
â”‚   â”œâ”€â”€ 01_preprocessing.ipynb
â”‚   â”œâ”€â”€ 02_vectorization_tfidf.ipynb
â”‚   â”œâ”€â”€ 03_classification_tfidf.ipynb
â”‚   â”œâ”€â”€ 04_clustering_tfidf.ipynb
â”‚   â”œâ”€â”€ 05_embeddings_gemini.ipynb
â”‚   â”œâ”€â”€ 06_classification_llm_embeddings.ipynb
â”‚   â”œâ”€â”€ 07_classification_embeddings.ipynb
â”‚   â””â”€â”€ 08_clustering_embeddings.ipynb
â”‚
â”œâ”€â”€ src/                  # MÃ³dulos Python reutilizÃ¡veis
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ vectorization.py
â”‚   â”œâ”€â”€ classification.py
â”‚   â””â”€â”€ clustering.py
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/          # Figuras (matrizes de confusÃ£o, UMAP, etc.)
â”‚   â””â”€â”€ metrics/          # MÃ©tricas salvas em CSV
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Criar e ativar ambiente virtual

**Windows (PowerShell):**
```powershell
python -m venv .venv
.venv\Scripts\activate
```

**Linux/Mac:**
```bash
python -m venv .venv
source .venv/bin/activate
```

### 2. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

**Nota sobre Python 3.14:** O `requirements.txt` agora tem suporte automÃ¡tico para diferentes versÃµes do Python:
- **Python 3.8-3.13**: `umap-learn` serÃ¡ instalado automaticamente
- **Python 3.14+**: `umap-learn` nÃ£o serÃ¡ instalado (mas o cÃ³digo usa t-SNE como fallback)

**InstalaÃ§Ã£o:**
```bash
pip install -r requirements.txt
```

**Se quiser UMAP no Python 3.14+** (opcional):
```bash
# 1. Instale primeiro o numba beta
pip install numba==0.63.0b1

# 2. Depois instale o umap-learn
pip install umap-learn
```

O cÃ³digo estÃ¡ preparado para usar **t-SNE automaticamente** como fallback quando UMAP nÃ£o estÃ¡ disponÃ­vel. Os notebooks funcionam perfeitamente com t-SNE!

### 3. Configurar chave da API do Google Gemini

**Windows (PowerShell):**
```powershell
$env:GEMINI_API_KEY = "SUA_CHAVE_AQUI"
```

**Linux/Mac:**
```bash
export GEMINI_API_KEY="SUA_CHAVE_AQUI"
```

**Alternativa:** Criar arquivo `.env` na raiz do projeto:
```
GEMINI_API_KEY=SUA_CHAVE_AQUI
```

> **Nota:** VocÃª pode obter uma chave de API gratuita em [Google AI Studio](https://makersuite.google.com/app/apikey).

---

## ğŸš€ ExecuÃ§Ã£o

Execute os notebooks na ordem sequencial:

```
01 â†’ 02 â†’ 03 â†’ 04 â†’ 05 â†’ 06 â†’ 07 â†’ 08
```

### DescriÃ§Ã£o dos Notebooks

1. **01_preprocessing.ipynb**: Carrega e prÃ©-processa os dados das 6 classes selecionadas
2. **02_vectorization_tfidf.ipynb**: Gera vetorizaÃ§Ã£o TF-IDF
3. **03_classification_tfidf.ipynb**: Classifica textos usando TF-IDF
4. **04_clustering_tfidf.ipynb**: Realiza clustering usando TF-IDF
5. **05_embeddings_gemini.ipynb**: Gera embeddings usando Google Gemini API ou Sentence-Transformers
6. **06_classification_llm_embeddings.ipynb**: Classifica textos usando embeddings via API com input dinÃ¢mico
7. **07_classification_embeddings.ipynb**: Classifica textos usando embeddings prÃ©-gerados
8. **08_clustering_embeddings.ipynb**: Realiza clustering usando embeddings

---

## ğŸ“Š Classes Utilizadas

- `rec.sport.baseball`
- `rec.sport.hockey`
- `talk.politics.mideast`
- `talk.politics.guns`
- `rec.autos`
- `sci.space`

---

## ğŸ“ˆ MÃ©tricas e Resultados

Os resultados sÃ£o salvos automaticamente em:

- **MÃ©tricas**: `/reports/metrics/*.csv`
- **Figuras**: `/reports/figures/*.png`

### MÃ©tricas de ClassificaÃ§Ã£o:
- Accuracy
- Macro F1-Score
- ValidaÃ§Ã£o cruzada (k=5)
- Matrizes de confusÃ£o

### MÃ©tricas de Clustering:
- Silhouette Score
- Davies-Bouldin Index
- VisualizaÃ§Ãµes UMAP 2D

---

## ğŸ§° Bibliotecas Principais

- **scikit-learn**: ClassificaÃ§Ã£o, clustering e prÃ©-processamento
- **google-generativeai**: GeraÃ§Ã£o de embeddings via API
- **umap-learn**: ReduÃ§Ã£o dimensional para visualizaÃ§Ã£o
- **pandas/numpy**: ManipulaÃ§Ã£o de dados
- **matplotlib/seaborn**: VisualizaÃ§Ã£o

---

## ğŸ“ Notas Importantes

1. **Reprodutibilidade**: Todos os processos usam `random_state=42` para garantir resultados reproduzÃ­veis
2. **Rate Limiting**: O notebook `05_embeddings_gemini.ipynb` inclui delays entre requisiÃ§Ãµes para evitar rate limiting
3. **Armazenamento**: Dados intermediÃ¡rios sÃ£o salvos em pickle para facilitar reprocessamento
4. **ComparaÃ§Ã£o**: Os resultados permitem comparar diretamente TF-IDF vs Embeddings

---

## ğŸ”® ExtensÃµes Futuras

- ExplicaÃ§Ã£o automÃ¡tica dos clusters via LLM (Groq ou Gemini)
- SumarizaÃ§Ã£o por tÃ³pico com prompts curtos
- ProtÃ³tipo Streamlit para interaÃ§Ã£o com parÃ¢metros e visualizaÃ§Ãµes dinÃ¢micas

---

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins acadÃªmicos como parte da disciplina ELE606 â€” TÃ³picos em IA.

---

## ğŸ‘¤ Autor

**CauÃ£ Vitor**  
UFRN â€” Departamento de Engenharia ElÃ©trica  
2025.2

