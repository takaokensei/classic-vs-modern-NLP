{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classifica√ß√£o com Embeddings LLM (Google Gemini)\n",
        "\n",
        "**Objetivo:** Gerar embeddings usando Google Gemini API com input din√¢mico do usu√°rio e executar classifica√ß√£o em tempo real.\n",
        "\n",
        "**Nota:** Este notebook permite configurar a chave de API dinamicamente e gerar embeddings + classifica√ß√£o em uma √∫nica execu√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "from tqdm import tqdm\n",
        "from google.api_core import exceptions as google_exceptions\n",
        "\n",
        "# Carregar vari√°veis de ambiente (opcional)\n",
        "load_dotenv()\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Input da Chave de API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURA√á√ÉO DA API - INSIRA SUA CHAVE AQUI\n",
        "# ============================================================================\n",
        "\n",
        "# Op√ß√£o 1: Chave hardcoded (apenas para testes locais)\n",
        "# api_key = \"SUA_CHAVE_AQUI\"\n",
        "\n",
        "# Op√ß√£o 2: Usar vari√°vel de ambiente\n",
        "# export GOOGLE_API_KEY=\"sua_chave_aqui\" (Linux/Mac)\n",
        "# $env:GOOGLE_API_KEY=\"sua_chave_aqui\" (Windows PowerShell)\n",
        "\n",
        "# Esta linha tentar√° carregar de vari√°vel de ambiente primeiro\n",
        "api_key = os.getenv('GOOGLE_API_KEY', None)\n",
        "\n",
        "if api_key is None:\n",
        "    print(\"‚ö†Ô∏è ATEN√á√ÉO: Chave de API n√£o configurada!\")\n",
        "    print(\"Configure uma das op√ß√µes abaixo:\")\n",
        "    print(\"1. Descomente e edite a linha 'api_key = SUA_CHAVE_AQUI' acima\")\n",
        "    print(\"2. Configure vari√°vel de ambiente GOOGLE_API_KEY\")\n",
        "    print(\"3. Obtenha uma chave gratuita em: https://makersuite.google.com/app/apikey\")\n",
        "else:\n",
        "    print(\"‚úÖ Chave de API carregada com sucesso!\")\n",
        "\n",
        "# Configurar o cliente Gemini\n",
        "if api_key:\n",
        "    genai.configure(api_key=api_key)\n",
        "    model_name = \"models/embedding-001\"\n",
        "    print(f\"Modelo selecionado: {model_name}\")\n",
        "else:\n",
        "    print(\"‚ùå N√£o √© poss√≠vel continuar sem chave de API!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carregar dataset pr√©-processado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar dados pr√©-processados\n",
        "with open('../data/processed/20news_preprocessed.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "X_text = data['text']\n",
        "y = data['target']\n",
        "target_names = data['target_names']\n",
        "\n",
        "print(f\"Total de documentos: {len(X_text)}\")\n",
        "print(f\"Classes: {target_names}\")\n",
        "print(f\"Distribui√ß√£o: {pd.Series(y).value_counts().sort_index().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Fun√ß√£o para gerar embeddings via API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_embeddings_batch(texts, model_name, batch_size=1, delay=2.0, use_tqdm=True):\n",
        "    \"\"\"\n",
        "    Gera embeddings com controle rigoroso de rate limiting.\n",
        "    \n",
        "    IMPORTANTE: A API gratuita do Gemini tem limite muito restritivo!\n",
        "    Se receber erro 429, voc√™ precisa:\n",
        "    1. Aguardar 24h para reset da quota di√°ria, OU\n",
        "    2. Usar um plano pago, OU\n",
        "    3. Processar texto por texto com delay maior (2+ segundos)\n",
        "    \n",
        "    Args:\n",
        "        texts: Lista de textos\n",
        "        model_name: Nome do modelo (ex: \"models/embedding-001\")\n",
        "        batch_size: Tamanho do lote (recomendado: 1 para free tier)\n",
        "        delay: Delay em segundos entre requisi√ß√µes (recomendado: 2.0+ para free tier)\n",
        "        use_tqdm: Se True, usa barra de progresso tqdm\n",
        "    \n",
        "    Returns:\n",
        "        Array numpy com embeddings\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    n_batches = (len(texts) + batch_size - 1) // batch_size\n",
        "    \n",
        "    print(f\"Gerando embeddings para {len(texts)} textos em {n_batches} lotes (batch_size={batch_size}, delay={delay}s)...\")\n",
        "    print(\"‚ö†Ô∏è Free tier tem limites restritivos. Processando lentamente...\")\n",
        "    \n",
        "    # Criar barra de progresso\n",
        "    if use_tqdm:\n",
        "        pbar = tqdm(total=len(texts), desc=\"Gerando embeddings\", unit=\"text\")\n",
        "    \n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        batch_num = i // batch_size + 1\n",
        "        max_retries = 3\n",
        "        retry_count = 0\n",
        "        success = False\n",
        "        \n",
        "        while retry_count < max_retries and not success:\n",
        "            try:\n",
        "                # Gerar embeddings para o lote\n",
        "                result = genai.embed_content(\n",
        "                    model=model_name,\n",
        "                    content=batch,\n",
        "                    task_type=\"RETRIEVAL_DOCUMENT\"\n",
        "                )\n",
        "                \n",
        "                # Extrair embeddings - a API pode retornar de diferentes formas\n",
        "                if isinstance(result, dict):\n",
        "                    if 'embedding' in result:\n",
        "                        batch_embeddings = result['embedding']\n",
        "                        if isinstance(batch_embeddings, list):\n",
        "                            if len(batch_embeddings) > 0 and isinstance(batch_embeddings[0], list):\n",
        "                                embeddings.extend(batch_embeddings)\n",
        "                            else:\n",
        "                                embeddings.extend([batch_embeddings])\n",
        "                        else:\n",
        "                            embeddings.append(batch_embeddings)\n",
        "                    else:\n",
        "                        batch_embeddings = list(result.values())[0] if result else []\n",
        "                        if isinstance(batch_embeddings, list):\n",
        "                            embeddings.extend(batch_embeddings if isinstance(batch_embeddings[0], list) else [batch_embeddings])\n",
        "                elif isinstance(result, list):\n",
        "                    embeddings.extend(result)\n",
        "                else:\n",
        "                    embeddings.append(result)\n",
        "                \n",
        "                success = True\n",
        "                if use_tqdm:\n",
        "                    pbar.update(len(batch))\n",
        "                else:\n",
        "                    if batch_num % 10 == 0 or batch_num == n_batches:\n",
        "                        print(f\"Lote {batch_num}/{n_batches} conclu√≠do ({len(batch)} embedding(s))\")\n",
        "                \n",
        "            except google_exceptions.ResourceExhausted as e:\n",
        "                error_msg = str(e)\n",
        "                if \"free_tier\" in error_msg.lower() or \"limit: 0\" in error_msg:\n",
        "                    if use_tqdm:\n",
        "                        pbar.close()\n",
        "                    print(f\"\\n{'='*60}\")\n",
        "                    print(\"‚ùå ERRO: Quota da API gratuita excedida!\")\n",
        "                    print(\"Solu√ß√µes:\")\n",
        "                    print(\"1. Aguardar 24h para reset da quota di√°ria\")\n",
        "                    print(\"2. Atualizar para plano pago no Google Cloud\")\n",
        "                    print(\"3. Verificar quota em: https://ai.dev/usage?tab=rate-limit\")\n",
        "                    print(f\"{'='*60}\")\n",
        "                    raise Exception(\"Quota da API gratuita excedida. Consulte https://ai.google.dev/gemini-api/docs/rate-limits\")\n",
        "                \n",
        "                wait_time = delay * (2 ** retry_count)\n",
        "                if use_tqdm:\n",
        "                    pbar.set_description(f\"Rate limit - aguardando {wait_time:.1f}s...\")\n",
        "                else:\n",
        "                    print(f\"Rate limit no lote {batch_num}. Aguardando {wait_time:.1f}s...\")\n",
        "                \n",
        "                time.sleep(wait_time)\n",
        "                retry_count += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_msg = str(e)\n",
        "                if \"429\" in error_msg or \"quota\" in error_msg.lower():\n",
        "                    wait_time = delay * (2 ** retry_count)\n",
        "                    if use_tqdm:\n",
        "                        pbar.set_description(f\"Erro 429 - aguardando {wait_time:.1f}s...\")\n",
        "                    else:\n",
        "                        print(f\"Erro 429 no lote {batch_num}. Aguardando {wait_time:.1f}s...\")\n",
        "                    time.sleep(wait_time)\n",
        "                    retry_count += 1\n",
        "                else:\n",
        "                    raise e\n",
        "        \n",
        "        if not success:\n",
        "            raise Exception(f\"Erro persistente no lote {batch_num} ap√≥s {max_retries} tentativas\")\n",
        "        \n",
        "        # Delay entre lotes\n",
        "        if i + batch_size < len(texts):\n",
        "            time.sleep(delay)\n",
        "    \n",
        "    if use_tqdm:\n",
        "        pbar.close()\n",
        "    \n",
        "    return np.array(embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Gerar embeddings via API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar se temos chave de API\n",
        "if not api_key:\n",
        "    print(\"‚ùå Interrompendo: chave de API necess√°ria para continuar\")\n",
        "else:\n",
        "    # Converter para lista de strings\n",
        "    texts_list = [str(text) for text in X_text]\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GERANDO EMBEDDINGS COM GOOGLE GEMINI API\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Total de textos: {len(texts_list)}\")\n",
        "    print(f\"Batch size: 1 (texto por texto)\")\n",
        "    print(f\"Delay entre requisi√ß√µes: 2.0 segundos\")\n",
        "    tempo_estimado = (len(texts_list) * 2.0) / 60\n",
        "    print(f\"Tempo estimado: ~{tempo_estimado:.1f} minutos\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "    \n",
        "    try:\n",
        "        X_emb = generate_embeddings_batch(\n",
        "            texts_list, \n",
        "            model_name, \n",
        "            batch_size=1,\n",
        "            delay=2.0,\n",
        "            use_tqdm=True\n",
        "        )\n",
        "        model_name_used = model_name\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"‚úÖ Embeddings gerados com sucesso!\")\n",
        "        print(f\"Shape: {X_emb.shape}\")\n",
        "        print(f\"Dimens√£o do embedding: {X_emb.shape[1]}\")\n",
        "        print(f\"Modelo: {model_name_used}\")\n",
        "        print(f\"{'='*60}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"‚ùå ERRO ao gerar embeddings:\")\n",
        "        print(str(e)[:300])\n",
        "        print(f\"{'='*60}\")\n",
        "        X_emb = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Divis√£o Treino/Teste (80/20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar se embeddings foram gerados\n",
        "if X_emb is None:\n",
        "    print(\"‚ùå Imposs√≠vel continuar sem embeddings\")\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_emb, y, \n",
        "        test_size=0.2, \n",
        "        random_state=42, \n",
        "        stratify=y\n",
        "    )\n",
        "    \n",
        "    print(f\"Treino: {X_train.shape[0]} documentos\")\n",
        "    print(f\"Teste: {X_test.shape[0]} documentos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Treinar e avaliar modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar se embeddings foram gerados\n",
        "if X_emb is None:\n",
        "    print(\"‚ùå Imposs√≠vel continuar sem embeddings\")\n",
        "else:\n",
        "    # Definir modelos\n",
        "    models = {\n",
        "        'GaussianNB': GaussianNB(),\n",
        "        'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),\n",
        "        'DecisionTree': DecisionTreeClassifier(random_state=42, max_depth=20),\n",
        "        'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)\n",
        "    }\n",
        "    \n",
        "    # Treinar e avaliar cada modelo\n",
        "    results = {}\n",
        "    predictions = {}\n",
        "    \n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Treinando {name}...\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Treinar\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # Prever\n",
        "        y_pred = model.predict(X_test)\n",
        "        predictions[name] = y_pred\n",
        "        \n",
        "        # Calcular m√©tricas\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "        \n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro\n",
        "        }\n",
        "        \n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Macro F1: {f1_macro:.4f}\")\n",
        "    \n",
        "    # Criar DataFrame com resultados\n",
        "    df_results = pd.DataFrame(results).T\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"üìä Resumo dos Resultados\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(df_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Valida√ß√£o Cruzada (k=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valida√ß√£o cruzada para cada modelo\n",
        "if X_emb is not None:\n",
        "    cv_results = {}\n",
        "    \n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nExecutando valida√ß√£o cruzada para {name}...\")\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')\n",
        "        cv_results[name] = {\n",
        "            'mean': cv_scores.mean(),\n",
        "            'std': cv_scores.std(),\n",
        "            'scores': cv_scores\n",
        "        }\n",
        "        print(f\"F1 Macro (CV): {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "    \n",
        "    # Criar DataFrame\n",
        "    df_cv = pd.DataFrame({\n",
        "        name: [cv_results[name]['mean'], cv_results[name]['std']]\n",
        "        for name in cv_results.keys()\n",
        "    }, index=['Mean', 'Std']).T\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"üìä Resultados da Valida√ß√£o Cruzada (F1 Macro)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(df_cv)\n",
        "else:\n",
        "    print(\"‚ùå Imposs√≠vel continuar sem embeddings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Matrizes de Confus√£o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotar matrizes de confus√£o\n",
        "if X_emb is not None:\n",
        "    # Criar diret√≥rio para figuras\n",
        "    os.makedirs('../reports/figures', exist_ok=True)\n",
        "    os.makedirs('../reports/metrics', exist_ok=True)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    for idx, (name, y_pred) in enumerate(predictions.items()):\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        \n",
        "        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "                    xticklabels=target_names, yticklabels=target_names,\n",
        "                    ax=axes[idx], cbar_kws={'label': 'Propor√ß√£o'})\n",
        "        axes[idx].set_title(f'{name}\\nAccuracy: {results[name][\"accuracy\"]:.3f}, F1: {results[name][\"f1_macro\"]:.3f}')\n",
        "        axes[idx].set_xlabel('Predito')\n",
        "        axes[idx].set_ylabel('Real')\n",
        "        axes[idx].tick_params(axis='x', rotation=45)\n",
        "        axes[idx].tick_params(axis='y', rotation=0)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../reports/figures/confusion_matrices_llm_embeddings.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ùå Imposs√≠vel continuar sem embeddings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Salvar resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar resultados\n",
        "if X_emb is not None:\n",
        "    # Salvar resultados em CSV\n",
        "    df_results.to_csv('../reports/metrics/classification_llm_embeddings_results.csv')\n",
        "    df_cv.to_csv('../reports/metrics/classification_llm_embeddings_cv.csv')\n",
        "    \n",
        "    print(\"‚úÖ Resultados salvos em:\")\n",
        "    print(\"  - ../reports/metrics/classification_llm_embeddings_results.csv\")\n",
        "    print(\"  - ../reports/metrics/classification_llm_embeddings_cv.csv\")\n",
        "    \n",
        "    # Gerar relat√≥rios detalhados por modelo\n",
        "    for name, y_pred in predictions.items():\n",
        "        report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
        "        df_report = pd.DataFrame(report).transpose()\n",
        "        filename = f'classification_llm_embeddings_{name.lower().replace(\" \", \"_\")}_report.csv'\n",
        "        df_report.to_csv(f'../reports/metrics/{filename}')\n",
        "        print(f\"  - ../reports/metrics/{filename}\")\n",
        "    \n",
        "    # Salvar embeddings se tudo deu certo\n",
        "    if X_emb is not None:\n",
        "        data_to_save = {\n",
        "            'X_emb': X_emb,\n",
        "            'y': y,\n",
        "            'target_names': target_names,\n",
        "            'model_name': model_name_used\n",
        "        }\n",
        "        output_path = '../data/processed/embeddings_llm_api.pkl'\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(data_to_save, f)\n",
        "        print(f\"\\n‚úÖ Embeddings salvos em: {output_path}\")\n",
        "else:\n",
        "    print(\"‚ùå Imposs√≠vel salvar resultados sem embeddings\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (ClassicVsModernNLP)",
      "language": "python",
      "name": "classicvsmodernnlp"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
